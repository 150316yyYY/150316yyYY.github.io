<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <title>Hexo - </title>
    
      <link rel="icon" href="/img/favicon.ico">
    
    <meta name="keyword"  content="">
    
<link rel="stylesheet" href="/css/style.css">

    
      
<link rel="stylesheet" href="/css/helpers.css">
    
    
  
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  


<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  <div class="loading-wrapper" data-loading="true">
    <div class="loading">
      <span></span>
      <span></span>
      <span></span>
    </div>
  </div>
  <div class="page" data-filter="true">
    <div class="head" data-show="true">
      <header class="head-header">
  <div class="head-author">
    <a href="/" class="head-author-link">
      Hexo</a>
    </div>
  <div class="head-right">
    <!-- <div class="head-search">
      <input class="head-searchK"></input>
      <span class="head-searchT">
        Search</span>
    </div> -->
    <button class="bar-wrap" id="bar-wrap-toggle">
      <span class="bar"></span>
      <span class="bar"></span>
      <span class="bar"></span>
    </button>
    <div class="head-about" id="head-about">
      
      <a class="head-about-link" href="/about">
        关于</a>
      
    </div>
  </div>
</header>

    </div>
    <div class="main">
      

<div class="menu-bar-head" id="menu-bar" data-show="false">
  <ul class="menu-bar-ul">
    
      
      <li class="menu-bar-item ">
          
              <a href="/categories/Posts/">
          
              <span>Posts1</span>
            </a>
      </li>
    
      
      <li class="menu-bar-item ">
          
              <a href="/categories/Posts2/">
          
              <span>Posts2</span>
            </a>
      </li>
    
      
      <li class="menu-bar-item  border ">
          
            <a href="/archives">
          
              <span>Archives</span>
            </a>
      </li>
    
      
      <li class="menu-bar-item ">
          
            <a href="/tags">
          
              <span>Tags</span>
            </a>
      </li>
    
    
      <li class="menu-bar-item">
        <a href="/about">
          <span>关于</span>
        </a>
      </li>
    
  </ul>
</div>
      <article class="post" id="post">
  <header class="post-head">
    <h1 class="post-title">
      <a class="title" href="/2023/06/07/spark/">
        “spark(local)”
      </a>
    </h1>
  </header>
  <div class="post-datetag">
    <div class="post-date">
      <time class="post-time" title="2023-06-07 13:35:15" datetime="2023-06-07T05:35:15.000Z" itemprop="datePublished">
  2023-06-07</time>
    </div>
    |
    <div class="post-tag">
      
    </div>
    |
    
  

    <div class="post-visit">
      <span id="busuanzi_container_page_pv">
        <span id="busuanzi_value_page_pv"></span>
        访问
      </span>
    </div>

  


  </div>

  
    <div class="post-word-count">
      

本文共658字。

    </div>
  

  
    <div class="post-cc">
      版权声明：
      
        署名-非商业性使用-相同方式共享 | <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/2.5/cn/">CC BY-NC-SA 2.5 CN</a>
      
    </div>
  

  


  <div class="article-entry" itemprop="articleBody">
    <span id="more"></span>

<p>四、Spark(local)<br>前提条件：拥有python和jdk。</p>
<p><img src="/2023/06/07/spark/a1.png" alt="spark"></p>
<p>第一步：上传Spark安装包<br>1.对于安装包的获取，共有两种途径方法。<br>1)方法一、通过md文档中提供的开源地址进行自主下载。<br>下载地址<br><a target="_blank" rel="noopener" href="https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz">https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz</a></p>
<p><img src="/2023/06/07/spark/a2.png" alt="spark"><br>2)方法二、通过老师所给的链接，从网盘下载相应组件安装包。</p>
<p>2.上传这个Spark安装包文件到Linux服务器中</p>
<p><img src="/2023/06/07/spark/a3.png" alt="img"></p>
<p>1)将其解压, 课程中将其解压(安装)到: <code>/export/server</code>内.<br><code>tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/</code></p>
<p><img src="/2023/06/07/spark/a4.png" alt="img"></p>
<p><img src="/2023/06/07/spark/a5.png" alt="img"></p>
<p><img src="/2023/06/07/spark/a6.png" alt="img"></p>
<p>2)由于spark目录名称很长, 给其一个软链接:<br>ln-s&#x2F;export&#x2F;server&#x2F;spark-3.2.0-bin-hadoop3.2 &#x2F;export&#x2F;server&#x2F;spark</p>
<p><img src="/2023/06/07/spark/a7.png" alt="img"></p>
<p>3)结果展示</p>
<p><img src="/2023/06/07/spark/a8.png" alt="img"></p>
<p><img src="/2023/06/07/spark/a9.png" alt="img"></p>
<p>第二步：配置环境变量<br>1.配置Spark时，由如下5个环境变量需要设置<br>SPARK_HOME: 表示Spark安装路径在哪里<br>PYSPARK_PYTHON: 表示Spark想运行Python程序, 那么去哪里找python执行器<br>JAVA_HOME: 告知Spark Java在哪里<br>HADOOP_CONF_DIR: 告知Spark Hadoop的配置文件在哪里<br>HADOOP_HOME: 告知Spark  Hadoop安装在哪里<br>2.这5个环境变量 都需要配置在: &#x2F;etc&#x2F;profile中</p>
<p><img src="/2023/06/07/spark/a10.png" alt="img"></p>
<p><img src="/2023/06/07/spark/a11.png" alt="img"><br>3.PYSPARK_PYTHON和 JAVA_HOME 需要同样配置在: <code>/root/.bashrc</code>中<br><img src="/2023/06/07/spark/a12.png" alt="img"></p>
<p>第三步、测试<br>1.测试bin&#x2F;pyspark程序<br>1)bin&#x2F;pyspark 程序, 可以提供一个  <code>交互式</code>的 Python解释器环境, 在这里面可以写普通python代码, 以及spark代码<br><img src="/2023/06/07/spark/a13.png" alt="img"></p>
<p>如图：<br><img src="/2023/06/07/spark/a14.png" alt="img"></p>
<p>2)在这个环境内, 可以运行spark代码<br>图中的: parallelize 和 map 都是spark提供的API<br>sc.parallelize([1,2,3,4,5]).map(lambda x: x + 1).collect()<br>2.测试WEB UI (4040)端口<br>1)Spark程序在运行的时候, 会绑定到机器的<code>4040</code>端口上.<br>如果4040端口被占用, 会顺延到4041 … 4042…<br><img src="/2023/06/07/spark/a15.png" alt="img"><br>2)4040端口是一个WEBUI端口, 可以在浏览器内打开:<br>输入:<code>服务器ip:4040</code> 即可打开:<br><img src="/2023/06/07/spark/a16.png" alt="img"><br><img src="/2023/06/07/spark/a17.png" alt="img"></p>
<p>3)打开监控页面后, 可以发现 在程序内仅有一个Driver<br>因为我们是Local模式, Driver即管理又干活.<br>4)同时, 输入jps<br><img src="/2023/06/07/spark/a18.png" alt="img"></p>
<p>5)可以看到local模式下的唯一进程存在<br>6)这个进程 即是master也是worker<br>3.测试bin&#x2F;spark-shell<br>1)同样是一个解释器环境, 和<code>bin/pyspark</code>不同的是, 这个解释器环境 运行的不是python代码, 而是scala程序代码<br><img src="/2023/06/07/spark/a19.png" alt="img"><br>2)这个仅作为了解即可, 因为这个是用于scala语言的解释器环境<br>4.测试bin&#x2F;spark-submit (PI)<br>1)作用:spark-submit 命令用来帮我们提交jar包给Spark 集群&#x2F;YARN ，让Spark 集群&#x2F;YARN去执行<br>使用方法:<br><img src="/2023/06/07/spark/a20.png" alt="img"><br>结果展示：<br><img src="/2023/06/07/spark/a20.png" alt="img"></p>

  </div>
</article>

    </div>
    <footer class="footer-nav">
      <div class="footer">
        <div class="back-top" id="back-top" title="Back to top">
          <i class="icon icon-chevron-bar-up"></i>
        </div>
        <span class="footer-msg">
  
    <div class="icp">
      <img src="/img/icp.png" alt="icp备案">
      <a href="https://beian.miit.gov.cn/" class="icp-text" target="_blank">
        京ICP备2021005293号
      </a>
    </div>
  

  

  
  

    <div>
      <span id="busuanzi_container_site_pv">
        <span id="busuanzi_value_site_pv">?</span> PV
      </span>
      <span id="busuanzi_container_site_uv">
        <span id="busuanzi_value_site_uv">?</span> UV
      </span>
    </div>

  



  Copyright &copy;
  2020
  
  
    <span class="timeDivide">-</span>
    2023
  
  John Doe.
  Power by
  <a href="https://hexo.io/" target="_blank" rel="external nofollow">Hexo</a>
  and
  <a href="https://github.com/Cerallin/hexo-theme-yuzu"
      target="_blank" rel="external nofollow" title="v2.4">
    Theme Yuzu</a>.
</span>

      </div>
    </footer>
    


<script src="/js/clipboard/clipboard.min.js"></script>


<script src="/js/theme.js"></script>


<script src="/js/index.js"></script>



  
  <script>
      expend = "展开";
      collapse = "收起";
  </script>
  
  
<script src="/js/toc.js"></script>





  </div>
</body>
